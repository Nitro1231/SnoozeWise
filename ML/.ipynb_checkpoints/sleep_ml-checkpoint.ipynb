{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2978856-826f-48ec-a3ab-6b0601311fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install coremltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e265b7b3-5f6d-4e38-9ba1-b39522be01a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikit-learn version 1.3.1 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "/Users/nitro/miniconda3/envs/cs178/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import coremltools as ct\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "743ac78c-eecd-4f42-b136-56ecb57e1247",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGE = {\n",
    "    'In Bed': 0,\n",
    "    'Awake': 1,\n",
    "    'REM': 2,\n",
    "    'Core': 3,\n",
    "    'Deep': 4,\n",
    "    'Unknown': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27430de8-50ec-47d6-8592-e67a3ff2cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path: str) -> dict:\n",
    "    with open(path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def parse_time(time: str) -> datetime:\n",
    "    return datetime.strptime(time, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def to_min(cur_time: datetime, start_time: datetime) -> int:\n",
    "    return int((cur_time - start_time).total_seconds()//60)\n",
    "\n",
    "def process_sleep_data(sleep_data: dict) -> dict:\n",
    "    stage_data = defaultdict(dict)\n",
    "\n",
    "    for data in sleep_data:\n",
    "        start_time = parse_time(data['start_time'])\n",
    "        end_time = parse_time(data['end_time'])\n",
    "        date = end_time.strftime('%Y-%m-%d')\n",
    "\n",
    "        if not date in stage_data: stage_data[date]['stages'] = list()\n",
    "        stage_data[date]['stages'].append({\n",
    "            'start_time': start_time,\n",
    "            'end_time': end_time,\n",
    "            'stage': STAGE[data['stage']]\n",
    "        })\n",
    "\n",
    "    for date, data in stage_data.items():\n",
    "        stage_data[date]['stages'] = sorted(data['stages'], key=lambda x: x['start_time'])\n",
    "        stage_data[date]['start_time'] = stage_data[date]['stages'][0]['start_time']\n",
    "        stage_data[date]['end_time'] = stage_data[date]['stages'][-1]['end_time']\n",
    "        stage_data[date]['day_of_week'] = stage_data[date]['start_time'].weekday()\n",
    "\n",
    "    return stage_data\n",
    "\n",
    "def post_process(stage_data: dict) -> pd.DataFrame:\n",
    "    ml_data = list()\n",
    "    for date, data in stage_data.items():\n",
    "        for item in data['stages']:\n",
    "            start_time = to_min(item['start_time'], data['start_time'])\n",
    "            end_time = to_min(item['end_time'], data['start_time'])\n",
    "            for time in range(start_time, end_time):\n",
    "                ml_data.append((\n",
    "                    date,\n",
    "                    data['day_of_week'],\n",
    "                    time,\n",
    "                    item['stage']\n",
    "                ))\n",
    "    return pd.DataFrame(ml_data, columns=['date', 'day_of_week', 'time', 'stage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "580e1b32-9785-4951-aef4-7b9ea32c1cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>time</th>\n",
       "      <th>stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756974</th>\n",
       "      <td>2021-09-22</td>\n",
       "      <td>2</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756975</th>\n",
       "      <td>2021-09-22</td>\n",
       "      <td>2</td>\n",
       "      <td>383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756976</th>\n",
       "      <td>2021-09-22</td>\n",
       "      <td>2</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756977</th>\n",
       "      <td>2021-09-22</td>\n",
       "      <td>2</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756978</th>\n",
       "      <td>2021-09-22</td>\n",
       "      <td>2</td>\n",
       "      <td>386</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>756979 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  day_of_week  time  stage\n",
       "0       2024-02-20            1     0      0\n",
       "1       2024-02-20            1     1      0\n",
       "2       2024-02-20            1     2      0\n",
       "3       2024-02-20            1     3      0\n",
       "4       2024-02-20            1    18      0\n",
       "...            ...          ...   ...    ...\n",
       "756974  2021-09-22            2   382      0\n",
       "756975  2021-09-22            2   383      0\n",
       "756976  2021-09-22            2   384      0\n",
       "756977  2021-09-22            2   385      0\n",
       "756978  2021-09-22            2   386      0\n",
       "\n",
       "[756979 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_json('./sleepData.json')\n",
    "data = data['sleep_data']\n",
    "\n",
    "stage_data = process_sleep_data(data)\n",
    "ml_data = post_process(stage_data)\n",
    "\n",
    "ml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3774065f-6972-4612-b5a0-6e6a35ef763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current backend accelerator: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('Current backend accelerator:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7200e14b-a6a1-48d5-a4c2-ecba65f1c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features and target\n",
    "X = ml_data[['day_of_week', 'time']].values\n",
    "y = ml_data['stage'].values\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a PyTorch Dataset\n",
    "class SleepStageDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "train_dataset = SleepStageDataset(X_train, y_train)\n",
    "val_dataset = SleepStageDataset(X_val, y_val)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed08ac5-4a39-41ac-a023-86203c258551",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, dim_model=128, num_heads=4, num_encoder_layers=3, dropout_rate=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding_layer = nn.Linear(num_features, dim_model)\n",
    "\n",
    "        self.positional_encoding = PositionalEncoding(dim_model, dropout_rate)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim_model, nhead=num_heads, dropout=dropout_rate)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Linear(dim_model, num_classes)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.embedding_layer(src)\n",
    "        src = src.unsqueeze(1)  # Add batch dimension\n",
    "        src = self.positional_encoding(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output.squeeze(1)  # Remove batch dimension\n",
    "        output = self.dropout(output)\n",
    "        output = self.classifier(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1d13828-daca-4233-9e0f-be9120b7bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}')\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ecc3b5a-45c6-4a15-b2b6-2bf8c53b1e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nitro/miniconda3/envs/cs178/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0003685374332502144\n",
      "Accuracy: 70.21849982826495%\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "num_features = 2  # day_of_week and time\n",
    "num_classes = len(set(y_train))  # Assuming y_train is accessible here\n",
    "\n",
    "# Initialize the model, criterion, and optimizer\n",
    "model = TransformerModel(num_features, num_classes)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train and evaluate the model\n",
    "train(model, train_loader, criterion, optimizer, num_epochs=10)\n",
    "evaluate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7e6e832-5f8c-44e1-8d78-818e5149df97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PyTorch Frontend ==> MIL Ops: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 257/258 [00:00<00:00, 7383.38 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 1160.89 passes/s]\n",
      "Running MIL default pipeline:   0%|                           | 0/71 [00:00<?, ? passes/s]/Users/nitro/miniconda3/envs/cs178/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:239: UserWarning: Input, 'src.1', of the source model, has been renamed to 'src_1' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL default pipeline: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:00<00:00, 250.97 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 1830.97 passes/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert to TorchScript\n",
    "model.eval()\n",
    "model.to('cpu')\n",
    "torch.save(model, 'pytorchmodel.pth')\n",
    "\n",
    "X_data, _ = list(train_loader)[0]\n",
    "\n",
    "traced_model = torch.jit.trace(model, X_data)\n",
    "traced_model.save('traced_model.pt')\n",
    "\n",
    "model = ct.convert(\n",
    "    traced_model,\n",
    "    convert_to='mlprogram',\n",
    "    inputs=[ct.TensorType(shape=X_data.shape)]\n",
    ")\n",
    " \n",
    "# Save the converted model.\n",
    "model.save('sleepCoreML.mlpackage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a9c1f6-391a-4355-b520-f73f754f91ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
