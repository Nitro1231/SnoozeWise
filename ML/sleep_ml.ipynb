{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2978856-826f-48ec-a3ab-6b0601311fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install coremltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e265b7b3-5f6d-4e38-9ba1-b39522be01a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "TensorFlow version 2.14.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import coremltools as ct\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "743ac78c-eecd-4f42-b136-56ecb57e1247",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGE = {\n",
    "    'In Bed': 0,\n",
    "    'Awake': 1,\n",
    "    'Asleep': 2,\n",
    "    'REM': 3,\n",
    "    'Core': 4,\n",
    "    'Deep': 5,\n",
    "    'Unknown': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27430de8-50ec-47d6-8592-e67a3ff2cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path: str) -> dict:\n",
    "    with open(path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def parse_time(time: str) -> datetime:\n",
    "    return datetime.strptime(time, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def to_min(cur_time: datetime, start_time: datetime) -> int:\n",
    "    return int((cur_time - start_time).total_seconds()//60)\n",
    "\n",
    "def process_sleep_data(sleep_data: dict) -> dict:\n",
    "    stage_data = defaultdict(dict)\n",
    "\n",
    "    for data in sleep_data:\n",
    "        if data['stage'] in ['Awake', 'REM', 'Core', 'Deep']:\n",
    "            start_time = parse_time(data['start_time'])\n",
    "            end_time = parse_time(data['end_time'])\n",
    "            date = end_time.strftime('%Y-%m-%d')\n",
    "    \n",
    "            if not date in stage_data: stage_data[date]['stages'] = list()\n",
    "            stage_data[date]['stages'].append({\n",
    "                'start_time': start_time,\n",
    "                'end_time': end_time,\n",
    "                'stage': STAGE[data['stage']]\n",
    "            })\n",
    "\n",
    "    for date, data in stage_data.items():\n",
    "        stage_data[date]['stages'] = sorted(data['stages'], key=lambda x: x['start_time'])\n",
    "        stage_data[date]['start_time'] = stage_data[date]['stages'][0]['start_time']\n",
    "        stage_data[date]['end_time'] = stage_data[date]['stages'][-1]['end_time']\n",
    "        stage_data[date]['day_of_week'] = stage_data[date]['start_time'].weekday()\n",
    "\n",
    "    return stage_data\n",
    "\n",
    "def post_process(stage_data: dict) -> pd.DataFrame:\n",
    "    ml_data = list()\n",
    "    for date, data in stage_data.items():\n",
    "        for item in data['stages']:\n",
    "            start_time = to_min(item['start_time'], data['start_time'])\n",
    "            end_time = to_min(item['end_time'], data['start_time'])\n",
    "            for time in range(start_time, end_time):\n",
    "                ml_data.append((\n",
    "                    date,\n",
    "                    data['day_of_week'],\n",
    "                    time,\n",
    "                    item['stage']\n",
    "                ))\n",
    "    return pd.DataFrame(ml_data, columns=['date', 'day_of_week', 'time', 'stage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "580e1b32-9785-4951-aef4-7b9ea32c1cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage\n",
      "4    109175\n",
      "3     53845\n",
      "5     27051\n",
      "1      4937\n",
      "Name: count, dtype: int64\n",
      "day_of_week\n",
      "1    30793\n",
      "0    29565\n",
      "4    29299\n",
      "2    28885\n",
      "3    27739\n",
      "6    26211\n",
      "5    22516\n",
      "Name: count, dtype: int64\n",
      "813\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>time</th>\n",
       "      <th>stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>1</td>\n",
       "      <td>201</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>1</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>1</td>\n",
       "      <td>204</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>1</td>\n",
       "      <td>395</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>1</td>\n",
       "      <td>396</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>1</td>\n",
       "      <td>397</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>1</td>\n",
       "      <td>398</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>1</td>\n",
       "      <td>399</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  day_of_week  time  stage\n",
       "200  2024-02-20            1   200      3\n",
       "201  2024-02-20            1   201      3\n",
       "202  2024-02-20            1   202      3\n",
       "203  2024-02-20            1   203      3\n",
       "204  2024-02-20            1   204      3\n",
       "..          ...          ...   ...    ...\n",
       "395  2024-02-20            1   395      4\n",
       "396  2024-02-20            1   396      4\n",
       "397  2024-02-20            1   397      4\n",
       "398  2024-02-20            1   398      4\n",
       "399  2024-02-20            1   399      4\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_json('./sleepData.json')\n",
    "data = data['sleep_data']\n",
    "\n",
    "stage_data = process_sleep_data(data)\n",
    "ml_data = post_process(stage_data)\n",
    "\n",
    "print(ml_data['stage'].value_counts())\n",
    "print(ml_data['day_of_week'].value_counts())\n",
    "print(max(ml_data['time']))\n",
    "ml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3774065f-6972-4612-b5a0-6e6a35ef763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current backend accelerator: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('Current backend accelerator:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7200e14b-a6a1-48d5-a4c2-ecba65f1c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features and target\n",
    "X = ml_data[['day_of_week', 'time']].values\n",
    "y = ml_data['stage'].values\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a PyTorch Dataset\n",
    "class SleepStageDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "train_dataset = SleepStageDataset(X_train, y_train)\n",
    "val_dataset = SleepStageDataset(X_val, y_val)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ed08ac5-4a39-41ac-a023-86203c258551",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, dim_model=128, num_heads=4, num_encoder_layers=3, dropout_rate=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding_layer = nn.Linear(num_features, dim_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim_model, nhead=num_heads, dropout=dropout_rate)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Linear(dim_model, num_classes)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.embedding_layer(src)\n",
    "        src = src.unsqueeze(1)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output.squeeze(1)\n",
    "        output = self.dropout(output)\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1d13828-daca-4233-9e0f-be9120b7bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}')\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ecc3b5a-45c6-4a15-b2b6-2bf8c53b1e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0587799029334635\n",
      "Accuracy: 55.97405261268653%\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "num_features = 2  # day_of_week and time\n",
    "num_classes = len(STAGE)  # Assuming y_train is accessible here\n",
    "\n",
    "# Initialize the model, criterion, and optimizer\n",
    "model = TransformerModel(num_features, num_classes)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train and evaluate the model\n",
    "train(model, train_loader, criterion, optimizer, num_epochs=1)\n",
    "evaluate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5cddd24-c379-4925-a85e-b79a71cf6bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.9295, -1.3123, -8.1016,  ...,  1.5704,  0.0349, -7.4154],\n",
      "        [-7.9295, -1.3123, -8.1016,  ...,  1.5704,  0.0349, -7.4154],\n",
      "        [-7.9295, -1.3123, -8.1016,  ...,  1.5704,  0.0349, -7.4154],\n",
      "        ...,\n",
      "        [-7.9295, -1.3123, -8.1017,  ...,  1.5704,  0.0349, -7.4154],\n",
      "        [-7.9295, -1.3123, -8.1017,  ...,  1.5704,  0.0349, -7.4154],\n",
      "        [-7.9295, -1.3123, -8.1017,  ...,  1.5704,  0.0349, -7.4154]],\n",
      "       device='mps:0')\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_input = torch.tensor([(i, 2) for i in range(0, 8 * 60)]).to(device).type(torch.float32)\n",
    "test_output = model(test_input)\n",
    "print(test_output.data)\n",
    "_, predicted = torch.max(test_output.data, 1)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e6e832-5f8c-44e1-8d78-818e5149df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TorchScript\n",
    "model.eval()\n",
    "model.to('cpu')\n",
    "torch.save(model, 'pytorchmodel.pth')\n",
    "\n",
    "X_data, _ = list(train_loader)[0]\n",
    "\n",
    "traced_model = torch.jit.trace(model, X_data)\n",
    "traced_model.save('traced_model.pt')\n",
    "\n",
    "model = ct.convert(\n",
    "    traced_model,\n",
    "    convert_to='mlprogram',\n",
    "    inputs=[ct.TensorType(shape=X_data.shape)]\n",
    ")\n",
    " \n",
    "# Save the converted model.\n",
    "model.save('sleepCoreML.mlpackage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a9c1f6-391a-4355-b520-f73f754f91ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
